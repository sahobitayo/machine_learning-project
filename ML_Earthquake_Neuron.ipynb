{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model - Using Neural Network Model to Make a Prediction of Mag and Depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.ipynb_checkpoints', 'data_base', 'ML_Earthquake_Neuron.ipynb', 'models', 'README.md']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../machine_learning-project\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>id</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19600102</td>\n",
       "      <td>-55.877</td>\n",
       "      <td>-1.890</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>iscgem877909</td>\n",
       "      <td>Bouvet Island region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19600103</td>\n",
       "      <td>43.700</td>\n",
       "      <td>84.542</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>iscgem877920</td>\n",
       "      <td>northern Xinjiang, China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19600104</td>\n",
       "      <td>11.374</td>\n",
       "      <td>42.609</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>iscgemsup877930</td>\n",
       "      <td>Djibouti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19600104</td>\n",
       "      <td>45.069</td>\n",
       "      <td>26.829</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>iscgemsup877933</td>\n",
       "      <td>Romania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19600107</td>\n",
       "      <td>6.418</td>\n",
       "      <td>94.756</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>iscgem877954</td>\n",
       "      <td>Nicobar Islands, India region</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  latitude  longitude  depth  mag               id  \\\n",
       "0  19600102   -55.877     -1.890   15.0  6.3     iscgem877909   \n",
       "1  19600103    43.700     84.542   15.0  5.7     iscgem877920   \n",
       "2  19600104    11.374     42.609   15.0  6.1  iscgemsup877930   \n",
       "3  19600104    45.069     26.829   40.0  5.4  iscgemsup877933   \n",
       "4  19600107     6.418     94.756   15.0  5.6     iscgem877954   \n",
       "\n",
       "                           place  \n",
       "0           Bouvet Island region  \n",
       "1       northern Xinjiang, China  \n",
       "2                       Djibouti  \n",
       "3                        Romania  \n",
       "4  Nicobar Islands, India region  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Data\n",
    "\n",
    "data = pd.read_csv(\"data_base/earthquakes.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'latitude', 'longitude', 'depth', 'mag', 'id', 'place'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the Columns\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19600102</td>\n",
       "      <td>-55.877</td>\n",
       "      <td>-1.890</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19600103</td>\n",
       "      <td>43.700</td>\n",
       "      <td>84.542</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19600104</td>\n",
       "      <td>11.374</td>\n",
       "      <td>42.609</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19600104</td>\n",
       "      <td>45.069</td>\n",
       "      <td>26.829</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19600107</td>\n",
       "      <td>6.418</td>\n",
       "      <td>94.756</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  latitude  longitude  depth  mag\n",
       "0  19600102   -55.877     -1.890   15.0  6.3\n",
       "1  19600103    43.700     84.542   15.0  5.7\n",
       "2  19600104    11.374     42.609   15.0  6.1\n",
       "3  19600104    45.069     26.829   40.0  5.4\n",
       "4  19600107     6.418     94.756   15.0  5.6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['date','latitude', 'longitude', 'depth', 'mag']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import time\n",
    "\n",
    "# timestamp = []\n",
    "# for d, t in zip(data['Date'], data['Time']):\n",
    "#     try:\n",
    "#         ts = datetime.datetime.strptime(d+' '+t, '%m/%d/%Y %H:%M:%S')\n",
    "#         timestamp.append(time.mktime(ts.timetuple()))\n",
    "#     except ValueError:\n",
    "#         # print('ValueError')\n",
    "#         timestamp.append('ValueError')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeStamp = pd.Series(timestamp)\n",
    "# data['Timestamp'] = timeStamp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Dropping the columns not needed\n",
    "\n",
    "# final_data = data.drop(['Date', 'Time'], axis=1)\n",
    "# final_data = final_data[final_data.Timestamp != 'ValueError']\n",
    "# final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "\n",
    "X = data[['date', 'latitude', 'longitude']]\n",
    "y = data[['mag', 'depth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60679, 3) (15170, 3) (60679, 2) (15170, 3)\n"
     ]
    }
   ],
   "source": [
    "#Splitting Xs and ys into traing and test datasets \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.326 , 566.1304],\n",
       "       [  5.572 ,  39.682 ],\n",
       "       [  5.205 ,  37.069 ],\n",
       "       ...,\n",
       "       [  5.43  ,  43.37  ],\n",
       "       [  5.594 ,  11.25  ],\n",
       "       [  5.149 ,  33.21  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg.fit(X_train, y_train)\n",
    "reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45738825747372863"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "\n",
    "reg.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.329  , 565.74184],\n",
       "       [  5.4768 ,  39.8714 ],\n",
       "       [  5.3046 ,  36.45974],\n",
       "       ...,\n",
       "       [  5.4344 ,  44.2416 ],\n",
       "       [  5.6732 ,  11.4206 ],\n",
       "       [  5.162  ,  33.486  ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators':[10, 20, 50, 100, 200, 500]}\n",
    "\n",
    "grid_obj = GridSearchCV(reg, parameters)\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "best_fit = grid_fit.best_estimator_\n",
    "best_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4615339695577431"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Best Fit \n",
    "\n",
    "best_fit.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit.score(X_test, y_test)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_model(neurons, activation, optimizer, loss):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_shape=(3,)))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# neurons = [16, 64, 128, 256]\n",
    "neurons = [16]\n",
    "# batch_size = [10, 20, 50, 100]\n",
    "batch_size = [10]\n",
    "epochs = [10]\n",
    "# activation = ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear', 'exponential']\n",
    "activation = ['sigmoid', 'relu']\n",
    "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "optimizer = ['SGD', 'Adadelta']\n",
    "loss = ['squared_hinge']\n",
    "\n",
    "param_grid = dict(neurons=neurons, batch_size=batch_size, epochs=epochs, activation=activation, optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.800000 using {'activation': 'sigmoid', 'batch_size': 10, 'epochs': 10, 'loss': 'squared_hinge', 'neurons': 16, 'optimizer': 'Adadelta'}\n",
      "0.000000 (0.000000) with: {'activation': 'sigmoid', 'batch_size': 10, 'epochs': 10, 'loss': 'squared_hinge', 'neurons': 16, 'optimizer': 'SGD'}\n",
      "0.800000 (0.400000) with: {'activation': 'sigmoid', 'batch_size': 10, 'epochs': 10, 'loss': 'squared_hinge', 'neurons': 16, 'optimizer': 'Adadelta'}\n",
      "0.000000 (0.000000) with: {'activation': 'relu', 'batch_size': 10, 'epochs': 10, 'loss': 'squared_hinge', 'neurons': 16, 'optimizer': 'SGD'}\n",
      "0.800000 (0.400000) with: {'activation': 'relu', 'batch_size': 10, 'epochs': 10, 'loss': 'squared_hinge', 'neurons': 16, 'optimizer': 'Adadelta'}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD', loss='squared_hinge', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6068/6068 [==============================] - 6s 951us/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 2/20\n",
      "6068/6068 [==============================] - 6s 956us/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 3/20\n",
      "6068/6068 [==============================] - 13s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 4/20\n",
      "6068/6068 [==============================] - 14s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 5/20\n",
      "6068/6068 [==============================] - 13s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 6/20\n",
      "6068/6068 [==============================] - 13s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 7/20\n",
      "6068/6068 [==============================] - 13s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 8/20\n",
      "6068/6068 [==============================] - 14s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 9/20\n",
      "6068/6068 [==============================] - 13s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 10/20\n",
      "6068/6068 [==============================] - 14s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 11/20\n",
      "6068/6068 [==============================] - 13s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 12/20\n",
      "6068/6068 [==============================] - 14s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 13/20\n",
      "6068/6068 [==============================] - 13s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 14/20\n",
      "6068/6068 [==============================] - 12s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 15/20\n",
      "6068/6068 [==============================] - 12s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 16/20\n",
      "6068/6068 [==============================] - 11s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 17/20\n",
      "6068/6068 [==============================] - 13s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 18/20\n",
      "6068/6068 [==============================] - 13s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 19/20\n",
      "6068/6068 [==============================] - 13s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n",
      "Epoch 20/20\n",
      "6068/6068 [==============================] - 13s 2ms/step - loss: 0.5027 - accuracy: 0.9850 - val_loss: 0.5028 - val_accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fbb264e8c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=10, epochs=20, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475/475 [==============================] - 1s 2ms/step - loss: 0.5028 - accuracy: 0.9848\n",
      "Evaluation result on Test Data : Loss = 0.5028371810913086, accuracy = 0.9848384857177734\n"
     ]
    }
   ],
   "source": [
    "[test_loss, test_acc] = model.evaluate(X_test, y_test)\n",
    "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/ml_model_fulldata.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "eq_model = load_model(\"models/ml_model_fulldata.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the loaded model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy = eq_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network -  Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda62cc632aa68244de81d94cca3d165e0a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
