{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Machine Learning Model - Trained with Truncated Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.ipynb_checkpoints', 'csv_results_to_geojson.ipynb', 'data_base', 'Evaluation Truncated Model Neural Network-FullData.ipynb', 'Evaluation Truncated Model Neural Network.ipynb', 'file.csv', 'get-pip.py', 'Images', 'Include', 'Lib', 'ML_Earthquake_Neuron-FullDataSet.ipynb', 'ML_Earthquake_Neuron_Trained with 20k.ipynb', 'ML_Earthquake_Neuron_Trained with Truncated Data with Months.ipynb', 'ML_Earthquake_Neuron_Trained with Truncated Data with Months_FullDataSet.ipynb', 'ML_Earthquake_Neuron_Trained with Truncated Data.ipynb', 'ML_Evaluating_Model.ipynb', 'ml_kellog_db.ipynb', 'ml_neuron_model_results.geojson', 'ml_results.csv', 'Model Information.docx', 'models', 'pyvenv.cfg', 'README.md', 'Scripts', '~$del Information.docx']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../machine_learning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>id</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1960</td>\n",
       "      <td>-60</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6.3</td>\n",
       "      <td>iscgem877909</td>\n",
       "      <td>Bouvet Island region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1960</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>5.7</td>\n",
       "      <td>iscgem877920</td>\n",
       "      <td>northern Xinjiang, China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1960</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>6.1</td>\n",
       "      <td>iscgemsup877930</td>\n",
       "      <td>Djibouti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1960</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>5.4</td>\n",
       "      <td>iscgemsup877933</td>\n",
       "      <td>Romania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1960</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>15</td>\n",
       "      <td>5.6</td>\n",
       "      <td>iscgem877954</td>\n",
       "      <td>Nicobar Islands, India region</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  latitude  longitude  depth  mag               id  \\\n",
       "0  1960       -60          0     15  6.3     iscgem877909   \n",
       "1  1960        40         80     15  5.7     iscgem877920   \n",
       "2  1960        10         40     15  6.1  iscgemsup877930   \n",
       "3  1960        50         30     40  5.4  iscgemsup877933   \n",
       "4  1960        10         90     15  5.6     iscgem877954   \n",
       "\n",
       "                           place  \n",
       "0           Bouvet Island region  \n",
       "1       northern Xinjiang, China  \n",
       "2                       Djibouti  \n",
       "3                        Romania  \n",
       "4  Nicobar Islands, India region  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Data\n",
    "\n",
    "data = pd.read_csv(\"data_base/USGS_earthquakes/earthquakes_truncated_testing_10k.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'latitude', 'longitude', 'depth', 'mag', 'id', 'place'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the Columns\n",
    "\n",
    "#After you've removed day and year\n",
    "\n",
    "mo_cat = CategoricalDtype(categories=[str(i) for i in range(1,13)], ordered=True)\n",
    "data.date.astype(mo_cat)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(i) for i in range(1,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1960</td>\n",
       "      <td>-60</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1960</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1960</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1960</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1960</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>15</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  latitude  longitude  depth  mag\n",
       "0  1960       -60          0     15  6.3\n",
       "1  1960        40         80     15  5.7\n",
       "2  1960        10         40     15  6.1\n",
       "3  1960        50         30     40  5.4\n",
       "4  1960        10         90     15  5.6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['date','latitude', 'longitude', 'depth', 'mag']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import time\n",
    "\n",
    "# timestamp = []\n",
    "# for d, t in zip(data['Date'], data['Time']):\n",
    "#     try:\n",
    "#         ts = datetime.datetime.strptime(d+' '+t, '%m/%d/%Y %H:%M:%S')\n",
    "#         timestamp.append(time.mktime(ts.timetuple()))\n",
    "#     except ValueError:\n",
    "#         # print('ValueError')\n",
    "#         timestamp.append('ValueError')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeStamp = pd.Series(timestamp)\n",
    "# data['Timestamp'] = timeStamp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Dropping the columns not needed\n",
    "\n",
    "# final_data = data.drop(['Date', 'Time'], axis=1)\n",
    "# final_data = final_data[final_data.Timestamp != 'ValueError']\n",
    "# final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "\n",
    "X = data[['date', 'latitude', 'longitude']]\n",
    "y = data[['mag', 'depth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 3) (2000, 3) (8000, 2) (2000, 3)\n"
     ]
    }
   ],
   "source": [
    "#Splitting Xs and ys into traing and test datasets \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.51009732, 37.8763142 ],\n",
       "       [ 5.41432865, 35.02163646],\n",
       "       [ 6.06724516, 41.85793207],\n",
       "       ...,\n",
       "       [ 5.41239087, 95.12953571],\n",
       "       [ 5.8169759 , 68.42683622],\n",
       "       [ 5.53159923, 53.75660442]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg.fit(X_train, y_train)\n",
    "reg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date  latitude  longitude\n",
      "6252  1974        60       -150\n",
      "4684  1973       -30        -70\n",
      "1731  1966       -60        -30\n",
      "4742  1973       -60        -30\n",
      "4521  1973        20        150\n",
      "...    ...       ...        ...\n",
      "6412  1974        30        140\n",
      "8285  1975       -10        110\n",
      "7853  1975       -40        180\n",
      "1095  1964        30        140\n",
      "6929  1975       -60        -30\n",
      "\n",
      "[2000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the Features that are going to be tested into the model\n",
    "\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4534966160531882"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating R Score\n",
    "\n",
    "reg.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.49564255, 37.9829169 ],\n",
       "       [ 5.42202227, 35.28443479],\n",
       "       [ 6.06758053, 43.29116173],\n",
       "       ...,\n",
       "       [ 5.3993346 , 96.04393615],\n",
       "       [ 5.78862196, 73.46328427],\n",
       "       [ 5.53559365, 53.67986942]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators':[10, 20, 50, 100, 200, 500]}\n",
    "\n",
    "grid_obj = GridSearchCV(reg, parameters)\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "best_fit = grid_fit.best_estimator_\n",
    "best_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4548109229924371"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Best Fit \n",
    "\n",
    "best_fit.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Neural Model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_model(neurons, activation, optimizer, loss):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_shape=(3,)))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# neurons = [16, 64, 128, 256]\n",
    "neurons = [16]\n",
    "# batch_size = [10, 20, 50, 100]\n",
    "batch_size = [10]\n",
    "epochs = [10]\n",
    "# activation = ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear', 'exponential']\n",
    "activation = ['sigmoid', 'relu']\n",
    "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "optimizer = ['SGD', 'Adadelta']\n",
    "loss = ['squared_hinge']\n",
    "\n",
    "param_grid = dict(neurons=neurons, batch_size=batch_size, epochs=epochs, activation=activation, optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.800000 using {'activation': 'relu', 'batch_size': 10, 'epochs': 10, 'loss': 'squared_hinge', 'neurons': 16, 'optimizer': 'SGD'}\n",
      "0.224750 (0.390577) with: {'activation': 'sigmoid', 'batch_size': 10, 'epochs': 10, 'loss': 'squared_hinge', 'neurons': 16, 'optimizer': 'SGD'}\n",
      "0.400000 (0.489898) with: {'activation': 'sigmoid', 'batch_size': 10, 'epochs': 10, 'loss': 'squared_hinge', 'neurons': 16, 'optimizer': 'Adadelta'}\n",
      "0.800000 (0.400000) with: {'activation': 'relu', 'batch_size': 10, 'epochs': 10, 'loss': 'squared_hinge', 'neurons': 16, 'optimizer': 'SGD'}\n",
      "0.340000 (0.427083) with: {'activation': 'relu', 'batch_size': 10, 'epochs': 10, 'loss': 'squared_hinge', 'neurons': 16, 'optimizer': 'Adadelta'}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD', loss='squared_hinge', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5031 - accuracy: 0.98 - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5020 - accuracy: 0.98 - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2128e6bffc8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=250, epochs=500, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.9825\n",
      "Evaluation result on Test Data : Loss = 0.503000020980835, accuracy = 0.9825000166893005\n"
     ]
    }
   ],
   "source": [
    "[test_loss, test_acc] = model.evaluate(X_test, y_test)\n",
    "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5026 - accuracy: 0.98 - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.98 - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5028 - accuracy: 0.98 - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.9841 - val_loss: 0.5030 - val_accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=250, epochs=500, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df5xXZZ338dc7ZhASEIXRyEHAwDtGQqWvRNItiP0A79T8kUl1Z5sr2Wa/XNswu9uW1ZV13Ttzc3NtI7N1Y82y0E3JB0Fte0M6qIPiiCKhDiCMZCiVP6Y+9x/nGjx8+QJf8HxnnJn38/H4Puac68f5XtdE8/G6rnPOpYjAzMysCK/r7gaYmVnv4aBiZmaFcVAxM7PCOKiYmVlhHFTMzKwwDipmZlYYBxWzfSRptKSQVFdF2Y9K+mVXtMvstcBBxXo1SeslvSRpeFn6AykwjO6elu3UlgMlbZf0k+5ui9mr5aBifcGvgdmdJ5LeAgzsvubs4mzgReDdkkZ05RdXM9oy2xcOKtYXfBf4SO78POCmfAFJB0m6SVK7pCckfUnS61JeP0lXS3pG0jrgf1Wo+y1JmyRtkHS5pH770L7zgOuBVcCHyq49UtIPU7u2Svp6Lu8CSa2Snpf0sKRJKT0kjc2Vu1HS5el4uqQ2SV+Q9DTwbUkHS7ojfcez6bgxV/8QSd+WtDHl/yilPyTp1Fy5+vQ7OnYf+m69jIOK9QUrgCGSxqc/9h8A/q2szD8BBwFHAtPIgtCfpbwLgPcCxwElspFF3neADmBsKvNu4M+raZikI4DpwM3p85FcXj/gDuAJYDRwOLAw5b0f+EoqPwQ4DdhazXcCbwAOAUYBc8j+Dnw7nR8B/AH4eq78d4HXA0cDhwJfTek3AR/OlTsF2BQRD1TZDuuNIsIff3rtB1gPvBP4EnAlMBO4G6gDguyPdT+y6aemXL2PA8vS8c+AC3N5705164DDUt2BufzZwNJ0/FHgl3to35eAB9LxG4E/Asel87cD7UBdhXqLgc/s5poBjM2d3whcno6nAy8BA/bQpmOBZ9PxCOBPwMEVyr0ReB4Yks5vBf6qu/8396d7P55Ptb7iu8AvgDGUTX0Bw4H+ZCOCTk+QjQwg++P5VFlep1FAPbBJUmfa68rK78lHgG8CRMRGST8nmw67HxgJPBERHRXqjQQer/I7yrVHxAudJ5JeTzb6mAkcnJIHp5HSSOA3EfFs+UVSe/8bOEvSbcAs4DP72SbrJTz9ZX1CRDxBtmB/CvDDsuxngJfJAkSnI4AN6XgT2R/XfF6np8hGKsMjYmj6DImIo/fWJkknAOOASyU9ndY43gbMTgvoTwFH7GYx/SngTbu59O/Jpqs6vaEsv/zV5H8J/A/gbRExBDixs4npew6RNHQ33/Udsimw9wPLI2LDbspZH+GgYn3J+cCMiPhdPjEi/gjcAlwhabCkUcDFvLLucgvwaUmNkg4G5ubqbgJ+CvyjpCGSXifpTZKmVdGe88im4prIppyOBSaQBYRZwD1kAW1+uu14gKSpqe6/ApdIeqsyY1O7AR4APphuMJhJtka0J4PJ1lF+K+kQ4K/L+ncn8M9pQb9e0om5uj8CJpGNUMpHgNYHOahYnxERj0dE826yPwX8DlgH/BL4d2BByvsm2RpGC3Afu450PkI2ffYw8CzZ2sIebw2WNAA4B/iniHg69/k12VTdeSnYnUp2A8CTQBvZTQZExPeBK1I7nyf7435IuvxnUr3fkt1N9qM9tQW4huwW62fIbmq4qyz/f5ON5B4BtgCf7cyIiD8APyCbViz/vVgfpAhv0mVm+0/Sl4GjIuLDey1svZ4X6s1sv6XpsvPJRjNmnv4ys/0j6QKyhfw7I+IX3d0ee22oaVCRNFPSGklrJc2tkD9K0hJJqyQtK3uK9ypJq9MTw9cqd79myl8k6aHc+T9IeiRd67Y93K1iZgWIiG9GxIERcWF3t8VeO2oWVNI97teR3cXSRHabZFNZsauBmyJiIjCP7OG0zlstpwITye6GOZ7cHSySzgS2l13rbmBCutajwKVF98nMzPaslmsqk4G1EbEOQNJC4HSyO2Q6NQGfS8dLeeUulQAGkN1RI7KHyzan6wwiu91zDtmtnlmFiJ/mrruCXV+lsYvhw4fH6NGj97FbZmZ928qVK5+JiIZKebUMKoez81PFbWQPduW1AGcBXwPOIHuKd1hELJe0lOwefQFfj4jWVOdvgX8ke8Brdz4G/EelDElzyAISRxxxBM3Nu7vD1MzMKpH0xO7yarmmogpp5fcvXwJMk3Q/2fTWBqAjvWF1PNBIFpxmSDoxvf10bETcttsvlS4je7nfzZXyI+KGiChFRKmhoWKgNTOz/VTLkUobO7/aohHYmC8QERuBM2HHtNZZEbEtjSZWRMT2lHcnMIXsIa+3Slqf2n6opGURMT2VO4/sbbInhx/AMTPrcrUcqdwLjJM0RlJ/4FxgUb6ApOFKe1aQLax3PsH8JNkIpk5SPdkopjUivhERb4yI0cA7gEdzAWUm8AXgtIjY09SYmZnVSM1GKhHRIekistdb9AMWRMRqSfOA5ohYRPYa7islBdkbZD+Zqt8KzAAeJJsyuysibt/LV34dOAC4O919vMK3OppZUV5++WXa2tp44YUX9l64lxgwYACNjY3U19dXXadPv6alVCqFF+rNrBq//vWvGTx4MMOGDaPssbleKSLYunUrzz//PGPGjNkpT9LKiChVqucn6s3MqvDCCy/0mYACIIlhw4bt88jMQcXMrEp9JaB02p/++oWS++Fvbl/Nwxuf6+5mmFkX+uRxA+nfXv4ij55rYH0/3jh0YOHXdVAxM+sBnv3NVj5y1qkAtG/ZTL9+/Thk2HAAfrB4Gf3799/rNb7w6Qv5+Kcv5sixR9WsnQ4q++GvT93rTrFm1su0trbypoZB3deAhkE8/NAqAL7yla8waNAgLrnkkp2KRAQRweteV3ll49bv/VvF9CJ5TcXMrAdbu3YtEyZM4MILL2TSpEls2rSJOXPmUCqVOProo5k3b96Osu94xzt44IEH6OjoYOjQocydO5djjjmGt7/97WzZsqWQ9nikYma2j2qxrtr0xiH7PQvy8MMP8+1vf5vrr78egPnz53PIIYfQ0dHBSSedxNlnn01T084vid+2bRvTpk1j/vz5XHzxxSxYsIC5c3fZoWSfeaRiZtbDvelNb+L444/fcf69732PSZMmMWnSJFpbW3n44Yd3qTNw4EBmzZoFwFvf+lbWr19fSFs8UjEz20evtXXVAw88cMfxY489xte+9jXuuecehg4dyoc//OGKz5rkF/b79etHR0dHIW3xSMXMrBd57rnnGDx4MEOGDGHTpk0sXry4S7/fIxUzs15k0qRJNDU1MWHCBI488kimTp3apd/vd3/53V9mVoXW1lbGjx/f3c3ocpX67Xd/mZlZl3BQMTOzwjiomJlZYWoaVCTNlLRG0lpJuzxVI2mUpCWSVklaJqkxl3eVpNWSWiVdq7LXZUpaJOmh3Pkhku6W9Fj6eXAt+2ZmZruqWVCR1A+4DpgFNAGzJTWVFbsauCkiJgLzgCtT3ROAqcBEYAJwPNmWwp3XPhMof13oXGBJRIwDlqRzMzPrQrUcqUwG1kbEuoh4CVgInF5WpoksAAAszeUHMADoT7ZFcD2wGUDSIOBi4PKya50OfCcdfwd4X2E9MTOzqtQyqBwOPJU7b0tpeS3AWen4DGCwpGERsZwsyGxKn8UR0ZrK/S3wj8Dvy651WERsAkg/D63UKElzJDVLam5vb9+/npmZdbHp06fv8iDjNddcw1/8xV/sts6gQV3/VuVaBpVKW4aVPxRzCTBN0v1k01sbgA5JY4HxQCNZIJoh6URJxwJjI+K2/W1URNwQEaWIKDU0NOzvZczMutTs2bNZuHDhTmkLFy5k9uzZ3dSiymoZVNqAkbnzRmBjvkBEbIyIMyPiOOCylLaNbNSyIiK2R8R24E5gCvB24K2S1gO/BI6StCxdbrOkEQDpZzHvcTYzew04++yzueOOO3jxxRcBWL9+PRs3buTYY4/l5JNPZtKkSbzlLW/hxz/+cbe2s5avabkXGCdpDNkI5Fzgg/kCkoYDv4mIPwGXAgtS1pPABZKuJBvxTAOuiYjbgW+kuqOBOyJieqqzCDgPmJ9+du9v1sx6rzvnwtMPFnvNN7wFZs3fbfawYcOYPHkyd911F6effjoLFy7kAx/4AAMHDuS2225jyJAhPPPMM0yZMoXTTjttv/aXL0LNRioR0QFcBCwGWoFbImK1pHmSTkvFpgNrJD0KHAZckdJvBR4HHiRbd2lJAWVP5gPvkvQY8K50bmbWa+SnwDqnviKCL37xi0ycOJF3vvOdbNiwgc2bN3dbG2v6QsmI+Anwk7K0L+eObyULIOX1/gh8fC/XXk92u3Hn+Vbg5FfXYjOzKuxhRFFL73vf+7j44ou57777+MMf/sCkSZO48cYbaW9vZ+XKldTX1zN69OiKr7rvKn6i3syshxg0aBDTp0/nYx/72I4F+m3btnHooYdSX1/P0qVLeeKJJ7q1jQ4qZmY9yOzZs2lpaeHcc88F4EMf+hDNzc2USiVuvvlm3vzmN3dr+7yfiplZD3LGGWeQ37Jk+PDhLF++vGLZ7dvLXzxSex6pmJlZYRxUzMysMA4qZmZV6ms75e5Pfx1UzMyqMGDAALZu3dpnAktEsHXrVgYMGLBP9bxQb2ZWhcbGRtra2uhLL6IdMGAAjY2Ney+Y46BiZlaF+vp6xowZ093NeM3z9JeZmRXGQcXMzArjoGJmZoVxUDEzs8I4qJiZWWEcVMzMrDAOKmZmVpiaBhVJMyWtkbRW0twK+aMkLZG0StIySY25vKskrZbUKulapb0xJd0lqSXlXS+pX0o/VtIKSQ9IapY0uZZ9MzOzXdUsqKQ/9tcBs4AmYLakprJiVwM3RcREYB5wZap7AjAVmEi2u+PxZPvUA5wTEcek9Abg/Sn9KuBvIuJY4Mvp3MzMulAtRyqTgbURsS4iXgIWAqeXlWkClqTjpbn8AAYA/YEDgHpgM0BEPJfK1KX8yNUZko4PAjYW2RkzM9u7WgaVw4GncudtKS2vBTgrHZ8BDJY0LCKWkwWZTemzOCJaOytJWgxsAZ7nlT3uPwv8g6SnyEZAl1ZqlKQ5aXqsuS+9w8fMrCvUMqioQlr56z0vAaZJup9semsD0CFpLDAeaCQLRDMknbjjIhHvAUaQjWJmpORPAJ+LiJHA54BvVWpURNwQEaWIKDU0NOx358zMbFe1DCptwMjceSNlU1IRsTEizoyI44DLUto2slHLiojYHhHbgTuBKWV1XwAW8cqU2XnAD9Px98mm38zMrAvVMqjcC4yTNEZSf+BcsiCwg6ThkjrbcCmwIB0/STaCqZNUTzaKaZU0SNKIVLcOOAV4JNXZyCuL+TOAx2rULzMz242avfo+IjokXQQsBvoBCyJitaR5QHNELAKmA1dKCuAXwCdT9VvJAsODZFNmd0XE7ZIOAxZJOiBd82fA9anOBcDXUrB5AZhTq76ZmVll6iu7mFVSKpWiubm5u5thZtajSFoZEaVKeX6i3szMCuOgYmZmhXFQMTOzwjiomJlZYRxUzMysMA4qZmZWGAcVMzMrjIOKmZkVxkHFzMwK46BiZmaFcVAxM7PCOKiYmVlhHFTMzKwwDipmZlYYBxUzMytMTYOKpJmS1khaK2luhfxRkpZIWiVpmaTGXN5VklZLapV0rSSl9LsktaS86yX1y9X5VPq+1ZKuqmXfzMxsVzULKumP/XXALKAJmC2pqazY1cBNETERmAdcmeqeAEwFJgITgON5ZavgcyLimJTeALw/1TmJbL/6iRFxdLq2mZl1oVqOVCYDayNiXUS8BCwk+6Of1wQsScdLc/kBDAD6AwcA9cBmgIh4LpWpS/mdW1d+ApgfES+mcluK7pCZme1ZLYPK4cBTufO2lJbXApyVjs8ABksaFhHLyYLMpvRZHBGtnZUkLQa2AM+T7WcPcBTwPyX9StLPJR1fqVGS5khqltTc3t7+6npoZmY7qWVQUYW0KDu/BJgm6X6y6a0NQIekscB4oJEsEM2QdOKOi0S8BxhBNoqZkZLrgIOBKcDngVs612F2akDEDRFRiohSQ0PDq+mfmZmVqWVQaQNG5s4bgY35AhGxMSLOjIjjgMtS2jayUcuKiNgeEduBO8mCRb7uC8AiXpkyawN+GJl7gD8Bw4vvlpmZ7U4tg8q9wDhJYyT1B84lCwI7SBouqbMNlwIL0vGTZCOYOkn1ZKOYVkmDJI1IdeuAU4BHUp0fkUYtko4iW295pma9MzOzXdQsqEREB3ARsBhoBW6JiNWS5kk6LRWbDqyR9ChwGHBFSr8VeBx4kGzdpSUibgcOBBZJWpXStwDXpzoLgCMlPUR2U8B5EVE+3WZmZjWkvvx3t1QqRXNzc3c3w8ysR5G0MiJKlfL8RL2ZmRXGQcXMzArjoGJmZoVxUDEzs8I4qJiZWWEcVMzMrDAOKmZmVhgHFTMzK4yDipmZFWavQUXSRZIO7orGmJlZz1bNSOUNwL2SbknbA1d6pb2Zmdneg0pEfAkYB3wL+CjwmKS/k/SmGrfNzMx6mKrWVNLbfp9Onw6yzbBulXRVDdtmZmY9TN3eCkj6NHAe2d4k/wp8PiJeTvugPAb8VW2baGZmPcVegwrZ7olnRsQT+cSI+JOk99amWWZm1hNVM/31E+A3nSeSBkt6G0BEtO6pYlrYXyNpraS5FfJHSVoiaZWkZZIac3lXSVotqVXStZ03CEi6S1JLyrteUr+ya14iKSR5K2Ezsy5WTVD5BrA9d/67lLZH6Y/9dcAsoAmYLamprNjVwE0RMRGYB1yZ6p4ATAUmAhOA48m2FAY4JyKOSekNwPtz3zkSeBfZdsRmZtbFqgkqym/LGxF/orpps8nA2ohYFxEvkW3xe3pZmSZgSTpemssPYADZPvMHAPXA5vT9z6UydSk/v3XlV8nWePrudpZmZt2omqCyTtKnJdWnz2eAdVXUOxx4KnfeltLyWoCz0vEZwGBJwyJiOVmQ2ZQ+i/NTbZIWk+1P/zzZfvakfe83RETLnholaY6kZknN7e3tVXTDzMyqVU1QuRA4AdhAFhjeBsypol6lhyTLRxCXANMk3U82vbUB6JA0FhgPNJIFohmSTtxxkYj3ACPIRjEzJL0euAz48t4aFRE3REQpIkoNDQ1VdMPMzKq112msiNgCnLsf124DRubOG4GNZdfeCJwJIGkQcFZEbJM0B1gREdtT3p3AFOAXubovSFpENmX2NDAGaEnr+Y3AfZImR8TT+9F2MzPbD9U8pzIAOB84mmydA4CI+Nheqt4LjJM0hmwEci7wwbJrDwd+k9ZpLgUWpKwngQskXUk24pkGXJMCz+CI2CSpDjgF+K+IeBA4NHfd9UApIp7ZW//MzKw41Ux/fZfs/V/vAX5ONgp4fm+VIqIDuAhYDLQCt0TEaknz0voHwHRgjaRHgcOAK1L6rcDjwINk6y4tEXE7cCCwSNKqlL4FuL6KPpiZWRdQ7sauygWk+yPiOEmrImKipHqyhfMZXdPE2imVStHc3NzdzTAz61EkrYyIUqW8akYqL6efv5U0ATgIGF1Q28zMrBep5nmTG9J+Kl8CFgGDgP9T01aZmVmPtMegkl4a+VxEPEt259WRXdIqMzPrkfY4/ZXuyrqoi9piZmY9XDVrKnenlzSOlHRI56fmLTMzsx6nmjWVzudRPplLCzwVZmZmZap5on5MVzTEzMx6vmqeqP9IpfSIuKn45piZWU9WzfTX8bnjAcDJwH2Ag4qZme2kmumvT+XPJR1E9uoWMzOznVRz91e53wPjim6ImZn1fNWsqdzOK/ugvI5st8ZbatkoMzPrmapZU7k6d9wBPBERbTVqj5mZ9WDVBJUngU0R8QKApIGSRkfE+pq2zMzMepxq1lS+D/wpd/7HlGZmZraTaoJKXUS81HmSjvvXrklmZtZTVRNU2nM7NSLpdKCqbXolzZS0RtJaSXMr5I+StETSKknLJDXm8q6StFpSq6RrlTafl3SXpJaUd72kfin9HyQ9kq51m6Sh1bTRzMyKU01QuRD4oqQnJT0JfAH4+N4qpT/21wGzyO4Ymy2pqazY1cBNETERmAdcmeqeAEwFJgITyB7AnJbqnBMRx6T0BuD9Kf1uYEK61qNke96bmVkXqubhx8eBKZIGkW0/vNf96ZPJwNqIWAcgaSFwOvBwrkwT8Ll0vBT4UefXkj293x8QUA9sTu15Ltf2/qksEfHT3HVXAGdX2U4zMyvIXkcqkv5O0tCI2B4Rz0s6WNLlVVz7cOCp3HlbSstrAc5Kx2cAgyUNi4jlZEFmU/osjojWXJsWA1uA54FbK3z3x4A7d9OfOZKaJTW3t7dX0Q0zM6tWNdNfsyLit50naRfIU6qopwppUXZ+CTBN0v1k01sbgA5JY4HxQCNZIJoh6cRcG94DjAAOAGbs9KXSZWTP09xcqVERcUNElCKi1NDQUEU3zMysWtUElX6SDug8kTSQ7I/53rQBI3PnjcDGfIGI2BgRZ0bEccBlKW0b2ahlRRodbScbdUwpq/sCsIhsSq2zbecB7wU+FBHlAczMzGqsmqDyb8ASSedLOp9sQfw7VdS7FxgnaYyk/sC5ZEFgB0nDJXW24VJgQTp+kmwEUyepnmwU0yppkKQRqW4d2YjpkXQ+k+wmgtMi4vdVtM/MzApWzUL9VZJWAe8km9K6CxhVRb0OSRcBi4F+wIKIWC1pHtAcEYuA6cCVkgL4Ba/sLnkr2bTWg2RTZndFxO2SDgMWpZFTP+BnwPWpztfJRlB3p7uPV0TEhVX8DszMrCCqZpZI0rHAB4FzgF8DP4iIr9e4bTVXKpWiubm5u5thZtajSFoZEaVKebsdqUg6imzKajawFfgPsiB0Uk1aaWZmPd6epr8eAf4LODUi1gJI+tweypuZWR+3p4X6s4CngaWSvinpZCrfJmxmZgbsIahExG0R8QHgzcAysiffD5P0DUnv7qL2mZlZD7LXW4oj4ncRcXNEvJfsWZMHgF1eDmlmZrZPe9RHxG8i4l8iYsbeS5uZWV+zT0HFzMxsTxxUzMysMA4qZmZWGAcVMzMrjIOKmZkVxkHFzMwK46BiZmaFcVAxM7PCOKiYmVlhahpUJM2UtEbSWkm7vNpF0ihJSyStkrRMUmMu7ypJqyW1SrpWaectSXdJakl510vql9IPkXS3pMfSz4Nr2TczM9tVzYJK+mN/HTALaAJmS2oqK3Y1cFNETATmAVemuicAU4GJwATgeLIthQHOiYhjUnoD8P6UPhdYEhHjgCX4/WRmZl2uliOVycDaiFgXES8BC4HTy8o0kQUAgKW5/AAGAP3JtgiuBzYDRMRzqUxdyu/cuvJ04Dvp+DvA+4rsjJmZ7V0tg8rhwFO587aUltdCtm8LwBnAYEnDImI5WZDZlD6LI6K1s5KkxcAW4Hmy/ewBDouITQDp56GVGiVpjqRmSc3t7e2vpn9mZlamlkGl0oZeUXZ+CTBN0v1k01sbgA5JY4HxZK/aPxyYIenEHReJeA8wgmwUs09vTI6IGyKiFBGlhoaGfalqZmZ7Ucug0gaMzJ03AhvzBSJiY0ScGRHHAZeltG1ko5YVEbE9IrYDdwJTyuq+ACzilSmzzZJGAKSfW4rvkpmZ7Uktg8q9wDhJYyT1B84lCwI7SBouqbMNlwIL0vGTZCOYOkn1ZKOYVkmDcoGjDjgFeCTVWQScl47PA35co36Zmdlu1CyoREQHcBGwGGgFbomI1ZLmSTotFZsOrJH0KHAYcEVKvxV4HHiQbN2lJSJuBw4EFklaldK3ANenOvOBd0l6DHhXOjczsy6kiPJljr6jVCpFc3NzdzfDzKxHkbQyIkqV8vxEvZmZFcZBxczMCuOgYmZmhXFQMTOzwjiomJlZYRxUzMysMA4qZmZWGAcVMzMrjIOKmZkVxkHFzMwK46BiZmaFcVAxM7PCOKiYmVlhHFTMzKwwDipmZlaYmgYVSTMlrZG0VtLcCvmjJC2RtErSMkmNubyrJK2W1CrpWmVeL+k/JT2S8ubnyh8haamk+9P1Tqll38zMbFc1CyqS+gHXAbOAJmC2pKayYlcDN0XERGAecGWqewIwFZgITACOJ9tSGODqiHgzcBwwVdKslP4lst0ljyPbuvifa9U3MzOrrJYjlcnA2ohYFxEvAQuB08vKNAFL0vHSXH4AA4D+wAFAPbA5In4fEUsB0jXvAxpzdYak44OAjYX3yMzM9qiWQeVw4KnceVtKy2sBzkrHZwCDJQ2LiOVkQWZT+iyOiNZ8RUlDgVN5JSh9BfiwpDbgJ8CnKjVK0hxJzZKa29vb97dvZmZWQS2DiiqkRdn5JcA0SfeTTW9tADokjQXGk41CDgdmSDpxx4WlOuB7wLURsS4lzwZujIhG4BTgu5J26V9E3BARpYgoNTQ0vLoempnZTmoZVNqAkbnzRsqmpCJiY0ScmdZBLktp28hGLSsiYntEbAfuBKbkqt4APBYR1+TSzgduSddYTjZ9NrzYLpmZ2Z7UMqjcC4yTNEZSf7LF80X5ApKG50YTlwIL0vGTZCOYOkn1ZKOY1lTncrI1k8+Wfd+TwMmpzHiyoOL5LTOzLlSzoBIRHcBFwGKygHBLRKyWNE/SaanYdGCNpEeBw4ArUvqtwOPAg2TrLi0RcXu65fgysgX++yQ9IOnPU52/BC6Q1EI2NfbRiCifbjMzsxpSX/67WyqVorm5ububYWbWo0haGRGlSnl+ot7MzArjoGJmZoVxUDEzs8I4qJiZWWEcVMzMrDAOKmZmVhgHFTMzK4yDipmZFcZBxczMCuOgYmZmhXFQMTOzwjiomJlZYRxUzMysMA4qZmZWGAcVMzMrjIOKmZkVpqZBRdJMSWskrZU0t0L+KElLJK2StCzt7NiZd5Wk1ZJaJV2rzOsl/aekR1Le/LLrnSPp4ZT377Xsm5mZ7apmQUVSP+A6YBbZ9r+zJTWVFbsauCkiJgLzgCtT3ROAqcBEYAJwPNk+9QBXR8SbgeOAqZJmpTrjyPa5nxoRR7PrHvZmZlZjtRypTAbWRtoYPaoAAAejSURBVMS6iHgJWAicXlamCViSjpfm8gMYAPQHDgDqgc0R8fuIWAqQrnkf0Dm6uQC4LiKeTflbatIrMzPbrVoGlcOBp3LnbSktrwU4Kx2fAQyWNCwilpMFmU3pszgiWvMVJQ0FTuWVoHQUcJSk/5a0QtLMSo2SNEdSs6Tm9vb2V9E9MzMrV8ugogppUXZ+CTBN0v1k01sbgA5JY4HxZKOQw4EZkk7ccWGpDvgecG1ErEvJdcA4YDowG/jXFHh2bkDEDRFRiohSQ0PDq+mfmZmVqWVQaQNG5s4bgY35AhGxMSLOjIjjgMtS2jayUcuKiNgeEduBO4Epuao3AI9FxDVl3/fjiHg5In4NrCELMmZm1kVqGVTuBcZJGiOpP3AusChfQNJwSZ1tuBRYkI6fJBvB1EmqJxvFtKY6lwMHsetC/I+AkzqvSzYdtg4zM+syNQsqEdEBXAQsJgsIt0TEaknzJJ2Wik0H1kh6FDgMuCKl3wo8DjxItu7SEhG3p1uOLyNb4L9P0gOS/jzVWQxslfQw2XrM5yNia636Z2Zmu1JE+TJH31EqlaK5ubm7m2Fm1qNIWhkRpUp5fqLezMwK46BiZmaFcVAxM7PCOKiYmVlhHFTMzKwwdd3dgB7pzrnw9IPd3Qozs/33hrfArPl7L7ePPFIxM7PCeKSyP2oQ3c3MegOPVMzMrDAOKmZmVhgHFTMzK4yDipmZFcZBxczMCuOgYmZmhXFQMTOzwjiomJlZYfr0Jl2S2oEn9rP6cOCZApvTE7jPfYP73De8mj6PioiGShl9Oqi8GpKad7fzWW/lPvcN7nPfUKs+e/rLzMwK46BiZmaFcVDZfzd0dwO6gfvcN7jPfUNN+uw1FTMzK4xHKmZmVhgHFTMzK4yDyn6QNFPSGklrJc3t7vYURdICSVskPZRLO0TS3ZIeSz8PTumSdG36HaySNKn7Wr7/JI2UtFRSq6TVkj6T0nttvyUNkHSPpJbU579J6WMk/Sr1+T8k9U/pB6TztSl/dHe2f39J6ifpfkl3pPNe3V8ASeslPSjpAUnNKa2m/7YdVPaRpH7AdcAsoAmYLampe1tVmBuBmWVpc4ElETEOWJLOIev/uPSZA3yji9pYtA7gLyNiPDAF+GT637M39/tFYEZEHAMcC8yUNAX4e+Crqc/PAuen8ucDz0bEWOCrqVxP9BmgNXfe2/vb6aSIODb3TEpt/21HhD/78AHeDizOnV8KXNrd7Sqwf6OBh3Lna4AR6XgEsCYd/wswu1K5nvwBfgy8q6/0G3g9cB/wNrKnq+tS+o5/58Bi4O3puC6VU3e3fR/72Zj+gM4A7gDUm/ub6/d6YHhZWk3/bXuksu8OB57KnbeltN7qsIjYBJB+HprSe93vIU1zHAf8il7e7zQV9ACwBbgbeBz4bUR0pCL5fu3oc8rfBgzr2ha/atcAfwX8KZ0Po3f3t1MAP5W0UtKclFbTf9t1r6KxfZUqpPXF+7J71e9B0iDgB8BnI+I5qVL3sqIV0npcvyPij8CxkoYCtwHjKxVLP3t0nyW9F9gSESslTe9MrlC0V/S3zNSI2CjpUOBuSY/soWwh/fZIZd+1ASNz543Axm5qS1fYLGkEQPq5JaX3mt+DpHqygHJzRPwwJff6fgNExG+BZWTrSUMldf6HZr5fO/qc8g8CftO1LX1VpgKnSVoPLCSbAruG3tvfHSJiY/q5hew/HiZT43/bDir77l5gXLpzpD9wLrCom9tUS4uA89LxeWRrDp3pH0l3jEwBtnUOqXsSZUOSbwGtEfF/c1m9tt+SGtIIBUkDgXeSLWAvBc5Oxcr73Pm7OBv4WaRJ954gIi6NiMaIGE32/9efRcSH6KX97STpQEmDO4+BdwMPUet/2929kNQTP8ApwKNk89CXdXd7CuzX94BNwMtk/9VyPtlc8hLgsfTzkFRWZHfBPQ48CJS6u/372ed3kA3xVwEPpM8pvbnfwETg/tTnh4Avp/QjgXuAtcD3gQNS+oB0vjblH9ndfXgVfZ8O3NEX+pv615I+qzv/VtX637Zf02JmZoXx9JeZmRXGQcXMzArjoGJmZoVxUDEzs8I4qJiZWWEcVMxqSNIf0xtiOz+FvdVa0mjl3iht9lrg17SY1dYfIuLY7m6EWVfxSMWsG6R9Lv4+7Wtyj6SxKX2UpCVpP4slko5I6YdJui3tgdIi6YR0qX6Svpn2RflpekLerNs4qJjV1sCy6a8P5PKei4jJwNfJ3kVFOr4pIiYCNwPXpvRrgZ9HtgfKJLInpCHb++K6iDga+C1wVo37Y7ZHfqLerIYkbY+IQRXS15NtlLUuvdDy6YgYJukZsj0sXk7pmyJiuKR2oDEiXsxdYzRwd2SbLSHpC0B9RFxe+56ZVeaRiln3id0c765MJS/mjv+I10mtmzmomHWfD+R+Lk/H/4/sTboAHwJ+mY6XAJ+AHRtsDemqRprtC/9XjVltDUw7LHa6KyI6bys+QNKvyP7jbnZK+zSwQNLngXbgz1L6Z4AbJJ1PNiL5BNkbpc1eU7ymYtYN0ppKKSKe6e62mBXJ019mZlYYj1TMzKwwHqmYmVlhHFTMzKwwDipmZlYYBxUzMyuMg4qZmRXm/wNoNy+vAN53fwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "# from tensorflow.keras.models import load_model\n",
    "# eq_model = load_model(\"models/ml_model_fulldata.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda62cc632aa68244de81d94cca3d165e0a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
